2024-11-27 12:19:58,627 - Loading training and testing data...
2024-11-27 12:19:58,659 - Creating Neural Network with learning rate=0.3, momentum=0.55, min_gradient=1e-5
2024-11-27 12:19:58,659 - Starting training for 100 epochs
2024-11-27 12:20:00,428 - Epoch 0, Loss: 519.7669126675416, Gradient_Hidden: [-20.34864774   5.16002698  -7.31590374], Gradient_Output: [-1.40864607 -5.9698649 ]
2024-11-27 12:20:02,030 - Epoch 1, Loss: 521.4958145868356, Gradient_Hidden: [-10.77571342   1.52256647  -1.3867731 ], Gradient_Output: [ 0.40898667 -0.05820183]
2024-11-27 12:20:03,629 - Epoch 2, Loss: 527.3822140994705, Gradient_Hidden: [-6.82762218  0.67406271  1.30821175], Gradient_Output: [0.22199593 0.05623656]
2024-11-27 12:20:05,227 - Epoch 3, Loss: 515.067337325996, Gradient_Hidden: [-5.0480538   0.07084835  8.06658992], Gradient_Output: [ 0.85124241 -0.49055531]
2024-11-27 12:20:06,827 - Epoch 4, Loss: 405.4638827124639, Gradient_Hidden: [-7.34286652 -1.20117547 20.31394689], Gradient_Output: [4.75160281 3.57651247]
2024-11-27 12:20:08,428 - Epoch 5, Loss: 352.1711623211604, Gradient_Hidden: [-4.55403572 -0.96467923 12.43331205], Gradient_Output: [0.66865481 0.53871169]
2024-11-27 12:20:10,028 - Epoch 6, Loss: 347.58005776546804, Gradient_Hidden: [-3.73785916 -0.80841544  8.16844554], Gradient_Output: [0.34960498 0.12514506]
2024-11-27 12:20:11,628 - Epoch 7, Loss: 346.22054852271845, Gradient_Hidden: [-3.35933347 -0.62288441  6.37540373], Gradient_Output: [0.20971511 0.07615095]
2024-11-27 12:20:13,231 - Epoch 8, Loss: 346.21774007303776, Gradient_Hidden: [-3.0874012  -0.49750538  5.29264347], Gradient_Output: [0.12579797 0.04030485]
2024-11-27 12:20:14,844 - Epoch 9, Loss: 346.88833813863124, Gradient_Hidden: [-2.86765785 -0.41615548  4.5528683 ], Gradient_Output: [0.08112654 0.02742818]
2024-11-27 12:20:16,446 - Epoch 10, Loss: 347.7475412759218, Gradient_Hidden: [-2.67498971 -0.35593763  4.01437995], Gradient_Output: [0.06042594 0.02115602]
2024-11-27 12:20:18,050 - Epoch 11, Loss: 348.3452555509211, Gradient_Hidden: [-2.49117109 -0.30709041  3.61629852], Gradient_Output: [0.05669333 0.01766901]
2024-11-27 12:20:19,654 - Epoch 12, Loss: 348.9286912030367, Gradient_Hidden: [-2.33808934 -0.27010699  3.31128486], Gradient_Output: [0.04425038 0.01353394]
2024-11-27 12:20:21,256 - Epoch 13, Loss: 349.87554822132245, Gradient_Hidden: [-2.21315704 -0.24445193  3.0442017 ], Gradient_Output: [0.02322584 0.00844853]
2024-11-27 12:20:22,855 - Epoch 14, Loss: 350.9210124066929, Gradient_Hidden: [-2.09708513 -0.22439874  2.81677934], Gradient_Output: [0.01419372 0.00470578]
2024-11-27 12:20:24,453 - Epoch 15, Loss: 351.9652113906816, Gradient_Hidden: [-1.9900967  -0.20733697  2.62314333], Gradient_Output: [0.01001221 0.00173637]
2024-11-27 12:20:26,051 - Epoch 16, Loss: 352.9863883346027, Gradient_Hidden: [-1.89156496 -0.19259426  2.45621328], Gradient_Output: [ 0.00716016 -0.00083147]
2024-11-27 12:20:27,647 - Epoch 17, Loss: 353.98253074795684, Gradient_Hidden: [-1.80082319 -0.17977412  2.31062988], Gradient_Output: [ 0.00482797 -0.00302304]
2024-11-27 12:20:29,242 - Epoch 18, Loss: 354.95455954554575, Gradient_Hidden: [-1.71725606 -0.16853194  2.18238546], Gradient_Output: [ 0.00285089 -0.00477218]
2024-11-27 12:20:30,844 - Epoch 19, Loss: 355.90331654644945, Gradient_Hidden: [-1.64023731 -0.15857227  2.06842731], Gradient_Output: [ 0.00116755 -0.00604663]
2024-11-27 12:20:32,442 - Epoch 20, Loss: 356.82942342871047, Gradient_Hidden: [-1.56911844 -0.14964853  1.96638851], Gradient_Output: [-0.00027222 -0.00688694]
2024-11-27 12:20:34,037 - Epoch 21, Loss: 357.7334412059913, Gradient_Hidden: [-1.50325488 -0.14156075  1.87440703], Gradient_Output: [-0.001513   -0.00739269]
2024-11-27 12:20:35,635 - Epoch 22, Loss: 358.61593792922883, Gradient_Hidden: [-1.44204704 -0.13415296  1.79100191], Gradient_Output: [-0.002592   -0.00768211]
2024-11-27 12:20:37,230 - Epoch 23, Loss: 359.4774902911719, Gradient_Hidden: [-1.38497152 -0.1273085   1.71498424], Gradient_Output: [-0.00353991 -0.00785503]
2024-11-27 12:20:38,826 - Epoch 24, Loss: 360.3186678101084, Gradient_Hidden: [-1.33159114 -0.12094273  1.64538985], Gradient_Output: [-0.00438191 -0.00797607]
2024-11-27 12:20:40,421 - Epoch 25, Loss: 361.14001455033133, Gradient_Hidden: [-1.2815475  -0.11499494  1.58142785], Gradient_Output: [-0.0051377  -0.00807603]
2024-11-27 12:20:42,018 - Epoch 26, Loss: 361.94202756405605, Gradient_Hidden: [-1.23454541 -0.10942096  1.52244157], Gradient_Output: [-0.00582088 -0.00816217]
2024-11-27 12:20:43,616 - Epoch 27, Loss: 362.72513305148817, Gradient_Hidden: [-1.1903368  -0.10418756  1.4678793 ], Gradient_Output: [-0.00643888 -0.00822939]
2024-11-27 12:20:45,217 - Epoch 28, Loss: 363.48966709123346, Gradient_Hidden: [-1.14870737 -0.09926846  1.41727248], Gradient_Output: [-0.0069938  -0.00826884]
2024-11-27 12:20:46,818 - Epoch 29, Loss: 364.2358701927472, Gradient_Hidden: [-1.10946697 -0.09464164  1.37021917], Gradient_Output: [-0.00748423 -0.00827295]
2024-11-27 12:20:48,419 - Epoch 30, Loss: 364.9639025540743, Gradient_Hidden: [-1.07244304 -0.09028767  1.32637142], Gradient_Output: [-0.00790737 -0.00823767]
2024-11-27 12:20:50,021 - Epoch 31, Loss: 365.67388109218405, Gradient_Hidden: [-1.03747637 -0.08618859  1.28542534], Gradient_Output: [-0.00826121 -0.00816272]
2024-11-27 12:20:51,621 - Epoch 32, Loss: 366.36593217184947, Gradient_Hidden: [-1.00441846 -0.08232737  1.2471133 ], Gradient_Output: [-0.00854614 -0.00805086]
2024-11-27 12:20:53,221 - Epoch 33, Loss: 367.0402479160412, Gradient_Hidden: [-0.97312974 -0.07868767  1.21119775], Gradient_Output: [-0.00876582 -0.0079068 ]
2024-11-27 12:20:54,820 - Epoch 34, Loss: 367.69713125131335, Gradient_Hidden: [-0.94347851 -0.07525379  1.17746634], Gradient_Output: [-0.00892724 -0.00773621]
2024-11-27 12:20:56,423 - Epoch 35, Loss: 368.3370165313514, Gradient_Hidden: [-0.91534018 -0.07201071  1.14572816], Gradient_Output: [-0.00904024 -0.00754486]
2024-11-27 12:20:58,023 - Epoch 36, Loss: 368.96045798634003, Gradient_Hidden: [-0.88859667 -0.06894415  1.11581078], Gradient_Output: [-0.00911646 -0.00733815]
2024-11-27 12:20:59,623 - Epoch 37, Loss: 369.56808515848957, Gradient_Hidden: [-0.86313585 -0.06604054  1.08755793], Gradient_Output: [-0.00916829 -0.00712088]
2024-11-27 12:21:01,225 - Epoch 38, Loss: 370.160530534878, Gradient_Hidden: [-0.83885106 -0.06328692  1.06082767], Gradient_Output: [-0.00920776 -0.00689719]
2024-11-27 12:21:02,828 - Epoch 39, Loss: 370.7383388231922, Gradient_Hidden: [-0.81564075 -0.06067073  1.03549083], Gradient_Output: [-0.00924559 -0.00667075]
2024-11-27 12:21:04,432 - Epoch 40, Loss: 371.3018711097078, Gradient_Hidden: [-0.79340846 -0.05817966  1.01142987], Gradient_Output: [-0.00929017 -0.00644502]
2024-11-27 12:21:06,036 - Epoch 41, Loss: 371.8512235434825, Gradient_Hidden: [-0.77206371 -0.05580162  0.98853805], Gradient_Output: [-0.00934644 -0.00622355]
2024-11-27 12:21:07,638 - Epoch 42, Loss: 372.3861902574777, Gradient_Hidden: [-0.75152381 -0.05352487  0.96671914], Gradient_Output: [-0.00941487 -0.00601021]
2024-11-27 12:21:09,242 - Epoch 43, Loss: 372.90630656303813, Gradient_Hidden: [-0.73171653 -0.05133841  0.94588729], Gradient_Output: [-0.00949082 -0.00580907]
2024-11-27 12:21:10,843 - Epoch 44, Loss: 373.41099344280616, Gradient_Hidden: [-0.71258294 -0.04923229  0.92596708], Gradient_Output: [-0.00956492 -0.00562398]
2024-11-27 12:21:12,444 - Epoch 45, Loss: 373.8997759024247, Gradient_Hidden: [-0.69407981 -0.04719801  0.90689317], Gradient_Output: [-0.00962457 -0.00545776]
2024-11-27 12:21:14,045 - Epoch 46, Loss: 374.372488550789, Gradient_Hidden: [-0.67618096 -0.045229    0.88860941], Gradient_Output: [-0.00965659 -0.00531129]
2024-11-27 12:21:15,644 - Epoch 47, Loss: 374.82937065974636, Gradient_Hidden: [-0.65887613 -0.04332125  0.87106731], Gradient_Output: [-0.00965066 -0.00518317]
2024-11-27 12:21:17,241 - Epoch 48, Loss: 375.2710198381605, Gradient_Hidden: [-0.64216604 -0.0414734   0.85422388], Gradient_Output: [-0.00960228 -0.00507013]
2024-11-27 12:21:18,836 - Epoch 49, Loss: 375.69826026718897, Gradient_Hidden: [-0.62605459 -0.03968596  0.8380396 ], Gradient_Output: [-0.00951371 -0.00496813]
2024-11-27 12:21:20,445 - Epoch 50, Loss: 376.1120069827511, Gradient_Hidden: [-0.61054137 -0.03796     0.82247705], Gradient_Output: [-0.00939241 -0.00487339]
2024-11-27 12:21:22,034 - Epoch 51, Loss: 376.51317120586464, Gradient_Hidden: [-0.59561767 -0.03629615  0.8075004 ], Gradient_Output: [-0.00924811 -0.00478307]
2024-11-27 12:21:23,624 - Epoch 52, Loss: 376.90260947151614, Gradient_Hidden: [-0.58126621 -0.0346941   0.79307548], Gradient_Output: [-0.00909018 -0.00469538]
2024-11-27 12:21:25,216 - Epoch 53, Loss: 377.28110223626607, Gradient_Hidden: [-0.56746333 -0.0331526   0.77917007], Gradient_Output: [-0.00892611 -0.00460934]
2024-11-27 12:21:26,808 - Epoch 54, Loss: 377.6493487249206, Gradient_Hidden: [-0.55418171 -0.03166976  0.76575406], Gradient_Output: [-0.00876118 -0.00452452]
2024-11-27 12:21:28,400 - Epoch 55, Loss: 378.00797004221494, Gradient_Hidden: [-0.54139272 -0.03024326  0.75279954], Gradient_Output: [-0.0085987  -0.00444084]
2024-11-27 12:21:29,992 - Epoch 56, Loss: 378.3575162529667, Gradient_Hidden: [-0.52906803 -0.02887064  0.74028075], Gradient_Output: [-0.00844051 -0.00435835]
2024-11-27 12:21:31,586 - Epoch 57, Loss: 378.6984750243837, Gradient_Hidden: [-0.5171805  -0.02754935  0.72817394], Gradient_Output: [-0.00828751 -0.0042772 ]
2024-11-27 12:21:33,183 - Epoch 58, Loss: 379.0312804250599, Gradient_Hidden: [-0.50570469 -0.02627692  0.71645718], Gradient_Output: [-0.00813997 -0.00419752]
2024-11-27 12:21:34,783 - Epoch 59, Loss: 379.3563211003315, Gradient_Hidden: [-0.494617   -0.02505096  0.70511025], Gradient_Output: [-0.00799781 -0.00411946]
2024-11-27 12:21:36,385 - Epoch 60, Loss: 379.67394746094953, Gradient_Hidden: [-0.48389562 -0.02386917  0.69411445], Gradient_Output: [-0.0078608  -0.00404311]
2024-11-27 12:21:37,986 - Epoch 61, Loss: 379.9844777853041, Gradient_Hidden: [-0.47352051 -0.02272941  0.68345244], Gradient_Output: [-0.0077286  -0.00396858]
2024-11-27 12:21:39,644 - Epoch 62, Loss: 380.28820328292977, Gradient_Hidden: [-0.46347318 -0.02162964  0.67310813], Gradient_Output: [-0.00760085 -0.00389591]
2024-11-27 12:21:41,680 - Epoch 63, Loss: 380.5853922360174, Gradient_Hidden: [-0.45373663 -0.02056796  0.66306652], Gradient_Output: [-0.00747721 -0.00382515]
2024-11-27 12:21:43,344 - Epoch 64, Loss: 380.8762933573987, Gradient_Hidden: [-0.44429517 -0.01954256  0.65331366], Gradient_Output: [-0.00735734 -0.00375632]
2024-11-27 12:21:45,095 - Epoch 65, Loss: 381.16113850078386, Gradient_Hidden: [-0.43513428 -0.01855178  0.64383649], Gradient_Output: [-0.00724096 -0.00368943]
2024-11-27 12:21:46,818 - Epoch 66, Loss: 381.4401448447558, Gradient_Hidden: [-0.42624053 -0.01759402  0.63462282], Gradient_Output: [-0.00712778 -0.00362447]
2024-11-27 12:21:48,548 - Epoch 67, Loss: 381.7135166544309, Gradient_Hidden: [-0.41760147 -0.01666782  0.62566119], Gradient_Output: [-0.00701758 -0.00356141]
2024-11-27 12:21:50,156 - Epoch 68, Loss: 381.98144670722803, Gradient_Hidden: [-0.4092055  -0.01577179  0.61694086], Gradient_Output: [-0.00691014 -0.00350023]
2024-11-27 12:21:51,768 - Epoch 69, Loss: 382.2441174532703, Gradient_Hidden: [-0.40104186 -0.0149046   0.60845173], Gradient_Output: [-0.00680529 -0.00344091]
2024-11-27 12:21:53,372 - Epoch 70, Loss: 382.50170196741925, Gradient_Hidden: [-0.39310047 -0.01406505  0.60018428], Gradient_Output: [-0.00670287 -0.00338338]
2024-11-27 12:21:55,002 - Epoch 71, Loss: 382.7543647384683, Gradient_Hidden: [-0.38537196 -0.01325197  0.59212955], Gradient_Output: [-0.00660273 -0.00332762]
2024-11-27 12:21:56,605 - Epoch 72, Loss: 383.0022623316357, Gradient_Hidden: [-0.37784753 -0.01246428  0.58427908], Gradient_Output: [-0.00650476 -0.00327358]
2024-11-27 12:21:58,217 - Epoch 73, Loss: 383.2455439526483, Gradient_Hidden: [-0.37051894 -0.01170094  0.57662485], Gradient_Output: [-0.00640885 -0.0032212 ]
2024-11-27 12:21:59,834 - Epoch 74, Loss: 383.4843519356865, Gradient_Hidden: [-0.36337848 -0.01096098  0.56915932], Gradient_Output: [-0.0063149  -0.00317044]
2024-11-27 12:22:01,435 - Epoch 75, Loss: 383.7188221720092, Gradient_Hidden: [-0.35641888 -0.01024349  0.56187531], Gradient_Output: [-0.00622285 -0.00312125]
2024-11-27 12:22:03,040 - Epoch 76, Loss: 383.94908449247094, Gradient_Hidden: [-0.34963331 -0.00954759  0.55476603], Gradient_Output: [-0.0061326  -0.00307357]
2024-11-27 12:22:04,682 - Epoch 77, Loss: 384.1752630136707, Gradient_Hidden: [-0.34301534 -0.00887246  0.54782504], Gradient_Output: [-0.00604411 -0.00302736]
2024-11-27 12:22:06,291 - Epoch 78, Loss: 384.3974764550137, Gradient_Hidden: [-0.33655889 -0.00821731  0.54104623], Gradient_Output: [-0.0059573  -0.00298257]
2024-11-27 12:22:08,008 - Epoch 79, Loss: 384.61583843218597, Gradient_Hidden: [-0.33025822 -0.0075814   0.53442377], Gradient_Output: [-0.00587214 -0.00293914]
2024-11-27 12:22:09,706 - Epoch 80, Loss: 384.83045773090976, Gradient_Hidden: [-0.32410793 -0.00696403  0.52795215], Gradient_Output: [-0.00578857 -0.00289704]
2024-11-27 12:22:11,457 - Epoch 81, Loss: 385.0414385639025, Gradient_Hidden: [-0.31810286 -0.00636451  0.5216261 ], Gradient_Output: [-0.00570655 -0.0028562 ]
2024-11-27 12:22:13,152 - Epoch 82, Loss: 385.2488808130315, Gradient_Hidden: [-0.31223816 -0.0057822   0.5154406 ], Gradient_Output: [-0.00562605 -0.0028166 ]
2024-11-27 12:22:14,876 - Epoch 83, Loss: 385.45288025814494, Gradient_Hidden: [-0.30650921 -0.0052165   0.50939089], Gradient_Output: [-0.00554702 -0.00277817]
2024-11-27 12:22:16,499 - Epoch 84, Loss: 385.65352879360006, Gradient_Hidden: [-0.30091161 -0.00466681  0.50347239], Gradient_Output: [-0.00546943 -0.00274089]
2024-11-27 12:22:18,103 - Epoch 85, Loss: 385.8509146335196, Gradient_Hidden: [-0.2954412  -0.00413258  0.49768077], Gradient_Output: [-0.00539325 -0.00270471]
2024-11-27 12:22:19,709 - Epoch 86, Loss: 386.045122505893, Gradient_Hidden: [-0.290094   -0.00361327  0.49201187], Gradient_Output: [-0.00531846 -0.00266958]
2024-11-27 12:22:21,313 - Epoch 87, Loss: 386.2362338365079, Gradient_Hidden: [-0.28486623 -0.00310837  0.4864617 ], Gradient_Output: [-0.00524502 -0.00263547]
2024-11-27 12:22:22,951 - Epoch 88, Loss: 386.42432692287656, Gradient_Hidden: [-0.27975427 -0.00261739  0.48102648], Gradient_Output: [-0.00517291 -0.00260235]
2024-11-27 12:22:24,583 - Epoch 89, Loss: 386.6094770985117, Gradient_Hidden: [-0.27475468 -0.00213986  0.47570257], Gradient_Output: [-0.0051021  -0.00257017]
2024-11-27 12:22:26,185 - Epoch 90, Loss: 386.79175688805987, Gradient_Hidden: [-0.26986415 -0.00167534  0.47048649], Gradient_Output: [-0.00503257 -0.00253891]
2024-11-27 12:22:27,789 - Epoch 91, Loss: 386.971236153554, Gradient_Hidden: [-0.26507953 -0.0012234   0.4653749 ], Gradient_Output: [-0.00496429 -0.00250852]
2024-11-27 12:22:29,515 - Epoch 92, Loss: 387.14798223215087, Gradient_Hidden: [-0.2603978  -0.00078362  0.46036461], Gradient_Output: [-0.00489725 -0.00247899]
2024-11-27 12:22:31,123 - Epoch 93, Loss: 387.3220600657681, Gradient_Hidden: [-2.55816061e-01 -3.55610310e-04  4.55452540e-01], Gradient_Output: [-0.00483141 -0.00245026]
2024-11-27 12:22:32,727 - Epoch 94, Loss: 387.49353232297136, Gradient_Hidden: [-2.51331535e-01  6.10082080e-05  4.50635761e-01], Gradient_Output: [-0.00476677 -0.00242233]
2024-11-27 12:22:34,330 - Epoch 95, Loss: 387.66245951347656, Gradient_Hidden: [-0.24694155  0.0004666   0.44591144], Gradient_Output: [-0.00470329 -0.00239515]
2024-11-27 12:22:35,933 - Epoch 96, Loss: 387.82890009564204, Gradient_Hidden: [-0.24264355  0.00086151  0.44127687], Gradient_Output: [-0.00464097 -0.0023687 ]
2024-11-27 12:22:37,536 - Epoch 97, Loss: 387.992910577367, Gradient_Hidden: [-0.23843507  0.00124608  0.43672944], Gradient_Output: [-0.00457976 -0.00234295]
2024-11-27 12:22:39,140 - Epoch 98, Loss: 388.15454561069566, Gradient_Hidden: [-0.23431372  0.00162063  0.43226664], Gradient_Output: [-0.00451967 -0.00231788]
2024-11-27 12:22:40,746 - Epoch 99, Loss: 388.3138580805929, Gradient_Hidden: [-0.23027723  0.00198546  0.42788607], Gradient_Output: [-0.00446067 -0.00229347]
2024-11-27 12:22:40,746 - Training completed
2024-11-27 12:22:40,746 - Starting testing phase
2024-11-27 12:22:40,746 - Using MSE threshold of 0.05 for accuracy calculation
2024-11-27 12:22:40,990 - Test Accuracy: 86.98%
2024-11-27 12:23:29,826 - Loading training and testing data...
2024-11-27 12:23:29,858 - Creating Neural Network with learning rate=0.3, momentum=0.55, min_gradient=1e-5
2024-11-27 12:23:29,858 - Starting training for 15 epochs
2024-11-27 12:23:31,481 - Epoch 0, Loss: 510.8086502657393, Gradient_Hidden: [ -7.77465765 -18.89698808   3.5682539 ], Gradient_Output: [-1.7097215  -5.35894843]
2024-11-27 12:23:33,107 - Epoch 1, Loss: 523.8874519863464, Gradient_Hidden: [  0.55570744 -11.28756607   1.33459498], Gradient_Output: [ 0.47042762 -0.06528083]
2024-11-27 12:23:34,736 - Epoch 2, Loss: 503.4160627474863, Gradient_Hidden: [ 7.56755181 -6.36060406  0.47783199], Gradient_Output: [ 0.69479366 -0.58582916]
2024-11-27 12:23:36,357 - Epoch 3, Loss: 403.87723686162883, Gradient_Hidden: [19.8487046  -8.03241666 -0.39909817], Gradient_Output: [5.24939957 3.47669936]
2024-11-27 12:23:37,982 - Epoch 4, Loss: 346.7691270490642, Gradient_Hidden: [11.95274339 -5.26718175 -0.90441105], Gradient_Output: [0.68440052 0.61158408]
2024-11-27 12:23:39,637 - Epoch 5, Loss: 343.69337477530377, Gradient_Hidden: [ 7.9593135  -4.31852992 -0.83648452], Gradient_Output: [0.30433505 0.16361823]
2024-11-27 12:23:41,267 - Epoch 6, Loss: 343.26751373301965, Gradient_Hidden: [ 6.26707234 -3.83563618 -0.66117786], Gradient_Output: [0.17068876 0.09374723]
2024-11-27 12:23:42,898 - Epoch 7, Loss: 343.88502675863595, Gradient_Hidden: [ 5.23361542 -3.48165563 -0.53476191], Gradient_Output: [0.09885727 0.05335247]
2024-11-27 12:23:44,521 - Epoch 8, Loss: 344.99993309803864, Gradient_Hidden: [ 4.51842741 -3.19616137 -0.44966449], Gradient_Output: [0.06151121 0.0384421 ]
2024-11-27 12:23:46,140 - Epoch 9, Loss: 346.2554272185261, Gradient_Hidden: [ 3.99053342 -2.95413221 -0.38637767], Gradient_Output: [0.04322989 0.03031959]
2024-11-27 12:23:47,766 - Epoch 10, Loss: 347.39332768597774, Gradient_Hidden: [ 3.5889217  -2.73904396 -0.33562587], Gradient_Output: [0.03802593 0.02516687]
2024-11-27 12:23:49,389 - Epoch 11, Loss: 348.1321585449008, Gradient_Hidden: [ 3.28709686 -2.53974169 -0.29313142], Gradient_Output: [0.04154109 0.02157621]
2024-11-27 12:23:51,015 - Epoch 12, Loss: 349.0418726512075, Gradient_Hidden: [ 3.03787576 -2.38689261 -0.26181639], Gradient_Output: [0.02551204 0.01636732]
2024-11-27 12:23:52,639 - Epoch 13, Loss: 350.15446344626895, Gradient_Hidden: [ 2.8147766  -2.25268441 -0.23914311], Gradient_Output: [0.01078413 0.01124053]
2024-11-27 12:23:54,273 - Epoch 14, Loss: 351.2815050584161, Gradient_Hidden: [ 2.62292867 -2.12871165 -0.22063343], Gradient_Output: [0.00588999 0.00735785]
2024-11-27 12:23:54,273 - Training completed
2024-11-27 12:23:54,273 - Starting testing phase
2024-11-27 12:23:54,273 - Using MSE threshold of 0.05 for accuracy calculation
2024-11-27 12:23:54,518 - Test Accuracy: 88.17%
2024-11-27 12:24:26,998 - Loading training and testing data...
2024-11-27 12:24:27,043 - Creating Neural Network with learning rate=0.3, momentum=0.55, min_gradient=1e-5
2024-11-27 12:24:27,043 - Starting training for 15 epochs
2024-11-27 12:24:28,747 - Epoch 0, Loss: 504.5476925763702, Gradient_Hidden: [ -7.13351507 -18.92467832   5.2400856 ], Gradient_Output: [-0.29092932 -5.53568241]
2024-11-27 12:24:30,349 - Epoch 1, Loss: 519.489139458331, Gradient_Hidden: [ -3.14372839 -12.09475984   2.05173317], Gradient_Output: [ 0.38728885 -0.01338519]
2024-11-27 12:24:31,953 - Epoch 2, Loss: 526.3138161536596, Gradient_Hidden: [-0.86062587 -7.33439732  0.75745768], Gradient_Output: [0.17132956 0.06888177]
2024-11-27 12:24:33,561 - Epoch 3, Loss: 529.3065391916465, Gradient_Hidden: [-0.35536942 -5.35692079  0.30506856], Gradient_Output: [0.09753186 0.06255481]
2024-11-27 12:24:35,166 - Epoch 4, Loss: 530.3576789607516, Gradient_Hidden: [-0.13974132 -4.33559664  0.11056062], Gradient_Output: [0.06102192 0.04964314]
2024-11-27 12:24:36,777 - Epoch 5, Loss: 530.6733770289907, Gradient_Hidden: [-0.01074188 -3.70170465  0.01657205], Gradient_Output: [0.04114982 0.04046819]
2024-11-27 12:24:38,388 - Epoch 6, Loss: 531.0036936382303, Gradient_Hidden: [ 0.10507654 -3.23992642 -0.03181083], Gradient_Output: [0.03046884 0.03510868]
2024-11-27 12:24:40,040 - Epoch 7, Loss: 531.3940896909583, Gradient_Hidden: [ 0.239511   -2.87728901 -0.05571569], Gradient_Output: [0.02471362 0.03179798]
2024-11-27 12:24:41,659 - Epoch 8, Loss: 531.7981571899909, Gradient_Hidden: [ 0.42985278 -2.58437178 -0.06528471], Gradient_Output: [0.02191524 0.02964269]
2024-11-27 12:24:43,262 - Epoch 9, Loss: 532.2037885603036, Gradient_Hidden: [ 0.77042271 -2.34437501 -0.0656669 ], Gradient_Output: [0.02252806 0.02898988]
2024-11-27 12:24:44,871 - Epoch 10, Loss: 532.6533247047429, Gradient_Hidden: [ 1.67532823 -2.15452601 -0.05566221], Gradient_Output: [0.03705773 0.03439724]
2024-11-27 12:24:46,507 - Epoch 11, Loss: 533.3109211202376, Gradient_Hidden: [ 6.96523398 -2.46453673 -0.03065825], Gradient_Output: [0.75273949 0.21795114]
2024-11-27 12:24:48,112 - Epoch 12, Loss: 504.23993527936557, Gradient_Hidden: [ 2.09589405 -0.91941353 -0.0991835 ], Gradient_Output: [-0.29347766 -0.27385939]
2024-11-27 12:24:49,721 - Epoch 13, Loss: 520.226257588973, Gradient_Hidden: [-1.69311429 -1.00153316  0.16872994], Gradient_Output: [-0.09995823 -0.0416947 ]
2024-11-27 12:24:51,330 - Epoch 14, Loss: 518.0687540564516, Gradient_Hidden: [-0.82097591 -1.17027527  0.07158257], Gradient_Output: [-0.0080448  -0.00753351]
2024-11-27 12:24:51,330 - Training completed
2024-11-27 12:24:51,330 - Starting testing phase
2024-11-27 12:24:51,330 - Using MSE threshold of 0.05 for accuracy calculation
2024-11-27 12:24:51,570 - Test Accuracy: 81.60%
2024-11-27 12:24:59,416 - Loading training and testing data...
2024-11-27 12:24:59,446 - Creating Neural Network with learning rate=0.3, momentum=0.55, min_gradient=1e-5
2024-11-27 12:24:59,447 - Starting training for 12 epochs
2024-11-27 12:25:01,065 - Epoch 0, Loss: 483.17947282861877, Gradient_Hidden: [  5.00741739 -12.4923326  -12.82738136], Gradient_Output: [-1.30275412 -4.60850074]
2024-11-27 12:25:02,697 - Epoch 1, Loss: 389.4470760903509, Gradient_Hidden: [ -3.43992277 -16.14714057 -13.63944239], Gradient_Output: [-0.33718718 -0.15259658]
2024-11-27 12:25:04,308 - Epoch 2, Loss: 334.2879553274157, Gradient_Hidden: [ -1.05459709  -9.19457044 -10.09870467], Gradient_Output: [ 0.3591012 -0.0095881]
2024-11-27 12:25:05,925 - Epoch 3, Loss: 339.7002755582367, Gradient_Hidden: [-0.75766113 -6.55440075 -6.92159015], Gradient_Output: [0.22574731 0.06139511]
2024-11-27 12:25:07,536 - Epoch 4, Loss: 346.85423601307747, Gradient_Hidden: [-0.54341662 -5.45163901 -5.59109527], Gradient_Output: [0.16564601 0.05088926]
2024-11-27 12:25:09,152 - Epoch 5, Loss: 352.1846868412364, Gradient_Hidden: [-0.39606922 -4.78097806 -4.78581334], Gradient_Output: [0.12627327 0.04394142]
2024-11-27 12:25:10,770 - Epoch 6, Loss: 356.46268974968496, Gradient_Hidden: [-0.30412596 -4.27956029 -4.21594248], Gradient_Output: [0.09837711 0.03950327]
2024-11-27 12:25:12,382 - Epoch 7, Loss: 360.24890957941426, Gradient_Hidden: [-0.24654781 -3.88288089 -3.77940593], Gradient_Output: [0.07973701 0.03508458]
2024-11-27 12:25:14,001 - Epoch 8, Loss: 363.7965565044508, Gradient_Hidden: [-0.2084761  -3.56803205 -3.43295945], Gradient_Output: [0.06657793 0.03123346]
2024-11-27 12:25:15,610 - Epoch 9, Loss: 367.2769017981968, Gradient_Hidden: [-0.18211359 -3.3121526  -3.14762714], Gradient_Output: [0.05664576 0.02793748]
2024-11-27 12:25:17,220 - Epoch 10, Loss: 370.42940489783916, Gradient_Hidden: [-0.16280242 -3.08578623 -2.90882895], Gradient_Output: [0.04879163 0.02522691]
2024-11-27 12:25:18,902 - Epoch 11, Loss: 373.0978199015161, Gradient_Hidden: [-0.14891697 -2.87717415 -2.70947183], Gradient_Output: [0.04242049 0.02325522]
2024-11-27 12:25:18,902 - Training completed
2024-11-27 12:25:18,902 - Starting testing phase
2024-11-27 12:25:18,902 - Using MSE threshold of 0.05 for accuracy calculation
2024-11-27 12:25:19,146 - Test Accuracy: 87.84%
2024-11-27 12:26:02,685 - Loading training and testing data...
2024-11-27 12:26:02,712 - Creating Neural Network with learning rate=0.3, momentum=0.55, min_gradient=1e-5
2024-11-27 12:26:02,713 - Starting training for 14 epochs
2024-11-27 12:26:04,335 - Epoch 0, Loss: 518.3179710255587, Gradient_Hidden: [  4.01331016  -4.45448823 -20.91099556], Gradient_Output: [-1.49672168 -4.18003266]
2024-11-27 12:26:05,942 - Epoch 1, Loss: 519.3396577303488, Gradient_Hidden: [  2.25588222  -5.61386237 -10.86715985], Gradient_Output: [ 0.54284515 -0.22392747]
2024-11-27 12:26:07,554 - Epoch 2, Loss: 526.6095776129756, Gradient_Hidden: [ 0.80909235 -2.02026343 -6.85514553], Gradient_Output: [0.17727009 0.03474947]
2024-11-27 12:26:09,166 - Epoch 3, Loss: 529.1942377451926, Gradient_Hidden: [ 0.33998923 -1.16961734 -5.1205068 ], Gradient_Output: [0.09481189 0.04932679]
2024-11-27 12:26:10,769 - Epoch 4, Loss: 530.0686946076596, Gradient_Hidden: [ 0.13629439 -0.77199592 -4.19531924], Gradient_Output: [0.05807051 0.04292864]
2024-11-27 12:26:12,371 - Epoch 5, Loss: 530.4212692299275, Gradient_Hidden: [ 0.03533292 -0.54668567 -3.60248293], Gradient_Output: [0.03889393 0.03657002]
2024-11-27 12:26:13,973 - Epoch 6, Loss: 530.8008201657623, Gradient_Hidden: [-0.01809839 -0.39762181 -3.16208093], Gradient_Output: [0.02854776 0.03244109]
2024-11-27 12:26:15,575 - Epoch 7, Loss: 531.2033431884714, Gradient_Hidden: [-0.04580029 -0.28947349 -2.81398346], Gradient_Output: [0.02252766 0.02946729]
2024-11-27 12:26:17,177 - Epoch 8, Loss: 531.5892228463126, Gradient_Hidden: [-0.05877097 -0.20508174 -2.53107627], Gradient_Output: [0.01864437 0.02701931]
2024-11-27 12:26:18,794 - Epoch 9, Loss: 531.9397312787805, Gradient_Hidden: [-0.06326282 -0.13446714 -2.29648605], Gradient_Output: [0.01592418 0.02490253]
2024-11-27 12:26:20,423 - Epoch 10, Loss: 532.249029381735, Gradient_Hidden: [-0.06291058 -0.07099946 -2.09893603], Gradient_Output: [0.013911   0.02304217]
2024-11-27 12:26:22,027 - Epoch 11, Loss: 532.5180444633617, Gradient_Hidden: [-0.05985525 -0.00946035 -1.93054723], Gradient_Output: [0.01237887 0.02140077]
2024-11-27 12:26:23,628 - Epoch 12, Loss: 532.7508078285083, Gradient_Hidden: [-0.05536765  0.05528903 -1.78557871], Gradient_Output: [0.01121733 0.01995854]
2024-11-27 12:26:25,234 - Epoch 13, Loss: 532.9525529965182, Gradient_Hidden: [-0.05019503  0.12975414 -1.65971371], Gradient_Output: [0.01038915 0.01870863]
2024-11-27 12:26:25,234 - Training completed
2024-11-27 12:26:25,234 - Starting testing phase
2024-11-27 12:26:25,234 - Using MSE threshold of 0.05 for accuracy calculation
2024-11-27 12:26:25,477 - Test Accuracy: 81.21%
2024-11-27 12:27:01,704 - Loading training and testing data...
2024-11-27 12:27:01,731 - Creating Neural Network with learning rate=0.3, momentum=0.55, min_gradient=1e-5
2024-11-27 12:27:01,732 - Starting training for 15 epochs
2024-11-27 12:27:03,338 - Epoch 0, Loss: 420.4122035119974, Gradient_Hidden: [  3.12285904 -14.31791103 -10.2347946 ], Gradient_Output: [-2.24210518 -2.45052026]
2024-11-27 12:27:04,948 - Epoch 1, Loss: 362.53767562248436, Gradient_Hidden: [  2.14920032 -12.85294466 -16.35655831], Gradient_Output: [ 0.95302023 -1.95096608]
2024-11-27 12:27:06,557 - Epoch 2, Loss: 331.937984250898, Gradient_Hidden: [  1.02959932  -9.35909116 -10.00423608], Gradient_Output: [ 0.50814561 -0.05113887]
2024-11-27 12:27:08,165 - Epoch 3, Loss: 339.04216877347653, Gradient_Hidden: [ 0.17835749 -6.83055624 -6.77286085], Gradient_Output: [0.27743032 0.06218292]
2024-11-27 12:27:09,773 - Epoch 4, Loss: 347.0325591833308, Gradient_Hidden: [-0.15262512 -5.64560734 -5.53837621], Gradient_Output: [0.17704307 0.05393992]
2024-11-27 12:27:11,385 - Epoch 5, Loss: 352.5676828998524, Gradient_Hidden: [-0.26904671 -4.88901738 -4.78868487], Gradient_Output: [0.12055726 0.0477412 ]
2024-11-27 12:27:12,994 - Epoch 6, Loss: 356.8164783804347, Gradient_Hidden: [-0.31537262 -4.3393068  -4.23678648], Gradient_Output: [0.09047883 0.04278032]
2024-11-27 12:27:14,601 - Epoch 7, Loss: 360.4812068618565, Gradient_Hidden: [-0.32830954 -3.91620658 -3.80470521], Gradient_Output: [0.0730189  0.03776413]
2024-11-27 12:27:16,207 - Epoch 8, Loss: 363.8695430322317, Gradient_Hidden: [-0.32553292 -3.58718627 -3.46038225], Gradient_Output: [0.06131836 0.03339533]
2024-11-27 12:27:17,816 - Epoch 9, Loss: 367.2386094684281, Gradient_Hidden: [-0.31648536 -3.32602564 -3.1765998 ], Gradient_Output: [0.0526018  0.02970626]
2024-11-27 12:27:19,422 - Epoch 10, Loss: 370.3261860787754, Gradient_Hidden: [-0.30335905 -3.09605468 -2.93669819], Gradient_Output: [0.04571704 0.02665309]
2024-11-27 12:27:21,032 - Epoch 11, Loss: 372.9387010513882, Gradient_Hidden: [-0.28901343 -2.8840731  -2.73524587], Gradient_Output: [0.04009086 0.02441516]
2024-11-27 12:27:22,640 - Epoch 12, Loss: 375.2214279513249, Gradient_Hidden: [-0.27450389 -2.69338105 -2.56279056], Gradient_Output: [0.03549988 0.02259514]
2024-11-27 12:27:24,251 - Epoch 13, Loss: 377.284101942762, Gradient_Hidden: [-0.26042816 -2.52347462 -2.41282828], Gradient_Output: [0.03169727 0.02101911]
2024-11-27 12:27:25,861 - Epoch 14, Loss: 379.1846362832552, Gradient_Hidden: [-0.24713109 -2.37174715 -2.28092866], Gradient_Output: [0.02849746 0.01964632]
2024-11-27 12:27:25,861 - Training completed
2024-11-27 12:27:25,861 - Starting testing phase
2024-11-27 12:27:25,861 - Using MSE threshold of 0.05 for accuracy calculation
2024-11-27 12:27:26,105 - Test Accuracy: 88.24%
2024-11-30 13:28:04,140 - Loading training and testing data...
2024-11-30 13:28:04,216 - Data loaded (shapes only), (80801, 2),(80801, 2)
2024-11-30 13:28:04,218 - Fold 1:
2024-11-30 13:35:53,226 - Loading training and testing data...
2024-11-30 13:35:53,303 - Data loaded (shapes only), (80801, 2),(80801, 2)
2024-11-30 13:35:53,304 - Fold 1:
2024-11-30 13:35:53,306 - Training in process:
2024-11-30 13:35:53,306 - size of hidden layer: 3, learning rate: 0.55, momentum: 0.5
2024-11-30 13:36:41,423 - Loading training and testing data...
2024-11-30 13:36:41,497 - Data loaded (shapes only), (80801, 2),(80801, 2)
2024-11-30 13:36:41,498 - Fold 1:
2024-11-30 13:36:41,500 - Training in process:
2024-11-30 13:36:41,501 - size of hidden layer: 3, learning rate: 0.55, momentum: 0.5
2024-11-30 13:38:25,610 - Loading training and testing data...
2024-11-30 13:38:25,682 - Data loaded (shapes only), (80801, 2),(80801, 2)
2024-11-30 13:38:25,684 - Fold 1:
2024-11-30 13:38:25,686 - Training in process:
2024-11-30 13:38:25,686 - size of hidden layer: 3, learning rate: 0.55, momentum: 0.5
2024-11-30 13:39:42,557 - Loading training and testing data...
2024-11-30 13:39:42,632 - Data loaded (shapes only), (80801, 2),(80801, 2)
2024-11-30 13:39:42,634 - Fold 1:
2024-11-30 13:39:42,635 - Training in process:
2024-11-30 13:39:42,636 - size of hidden layer: 3, learning rate: 0.55, momentum: 0.5
2024-11-30 13:42:08,704 - Loading training and testing data...
2024-11-30 13:42:08,779 - Data loaded (shapes only), (80801, 2),(80801, 2)
2024-11-30 13:42:08,781 - Fold 1:
2024-11-30 13:42:08,783 - Training in process:
2024-11-30 13:42:08,783 - size of hidden layer: 3, learning rate: 0.55, momentum: 0.5
2024-11-30 13:42:19,530 - Loading training and testing data...
2024-11-30 13:42:19,604 - Data loaded (shapes only), (80801, 2),(80801, 2)
2024-11-30 13:42:19,606 - Fold 1:
2024-11-30 13:42:19,608 - Training in process:
2024-11-30 13:42:19,608 - size of hidden layer: 3, learning rate: 0.55, momentum: 0.5
2024-11-30 13:43:51,661 - Loading training and testing data...
2024-11-30 13:43:51,692 - Data loaded (shapes only), (80800, 2),(80800, 2)
2024-11-30 13:43:51,694 - Fold 1:
2024-11-30 13:43:51,695 - Training in process:
2024-11-30 13:43:51,696 - size of hidden layer: 3, learning rate: 0.55, momentum: 0.5
2024-11-30 13:43:53,521 -      Fold 1,Epoch 0, Loss: 407.08658612825695, Gradient_Hidden: [ 1.12606819 -3.11018287  9.77354404], Gradient_Output: [-0.35197575 -0.43962728]
2024-11-30 13:43:55,356 -      Fold 1,Epoch 1, Loss: 281.60832186404235, Gradient_Hidden: [  0.66608149 -14.93299766   8.089121  ], Gradient_Output: [ 3.76631107 -1.45383998]
2024-11-30 13:43:57,201 -      Fold 1,Epoch 2, Loss: 234.59418268630526, Gradient_Hidden: [-1.1339791  -6.42473217  5.55713615], Gradient_Output: [0.11720194 0.20224715]
2024-11-30 13:43:59,037 -      Fold 1,Epoch 3, Loss: 234.7495335125601, Gradient_Hidden: [-0.61408202 -4.51409658  4.3823417 ], Gradient_Output: [-0.01491844  0.12559185]
2024-11-30 13:44:00,868 -      Fold 1,Epoch 4, Loss: 235.0175328878452, Gradient_Hidden: [-0.38999899 -3.66952108  3.74527494], Gradient_Output: [0.10637791 0.09573969]
2024-11-30 13:44:02,691 -      Fold 1,Epoch 5, Loss: 234.30674927789963, Gradient_Hidden: [-0.23861421 -3.17687267  3.27994234], Gradient_Output: [0.11496277 0.0635544 ]
2024-11-30 13:44:04,525 -      Fold 1,Epoch 6, Loss: 233.51451442727458, Gradient_Hidden: [-0.15348916 -2.8269124   2.94172908], Gradient_Output: [0.09009061 0.04221401]
2024-11-30 13:44:06,368 -      Fold 1,Epoch 7, Loss: 233.59224242141227, Gradient_Hidden: [-0.11113618 -2.58956142  2.70246318], Gradient_Output: [0.06830747 0.03020464]
2024-11-30 13:44:08,194 -      Fold 1,Epoch 8, Loss: 234.2739002369269, Gradient_Hidden: [-0.09211556 -2.37854382  2.48102763], Gradient_Output: [0.04062668 0.02168439]
2024-11-30 13:44:10,026 -      Fold 1,Epoch 9, Loss: 234.7928512644411, Gradient_Hidden: [-0.08504026 -2.18854852  2.2963934 ], Gradient_Output: [0.03439407 0.01517702]
2024-11-30 13:44:11,890 -      Fold 1,Epoch 10, Loss: 235.32668826531415, Gradient_Hidden: [-0.07934186 -2.02800124  2.14237279], Gradient_Output: [0.02921179 0.01027817]
2024-11-30 13:44:13,715 -      Fold 1,Epoch 11, Loss: 235.85830593487003, Gradient_Hidden: [-0.0752319  -1.8900504   2.01204627], Gradient_Output: [0.02523743 0.00592333]
2024-11-30 13:44:15,547 -      Fold 1,Epoch 12, Loss: 236.37165454897308, Gradient_Hidden: [-0.07246032 -1.76964362  1.89948771], Gradient_Output: [0.02253025 0.0016445 ]
2024-11-30 13:44:17,387 -      Fold 1,Epoch 13, Loss: 236.87252267972647, Gradient_Hidden: [-0.07074358 -1.66335031  1.80034119], Gradient_Output: [ 0.02013257 -0.0028372 ]
2024-11-30 13:44:19,221 -      Fold 1,Epoch 14, Loss: 237.36774863437333, Gradient_Hidden: [-0.06978814 -1.56890854  1.71201645], Gradient_Output: [ 0.0177853  -0.00722106]
2024-11-30 13:44:19,221 - Training completed
2024-11-30 13:44:19,221 - Testing in process:
2024-11-30 13:44:19,221 - Using MSE threshold of 0.05 for accuracy calculation
2024-11-30 13:44:19,348 - Fold 1 Test Accuracy: 86.46%
2024-11-30 13:44:19,348 - Fold 2:
